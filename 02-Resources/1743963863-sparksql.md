---
id: 1743963863-sparksql
aliases:
  - sparksql
  - Sparksql
  - SparkSQL
tags:
  - #resource
  - python
created_date: "2025-04-06"
link: "[[1743811421-procesamiento-de-datos-masivos|procesamiento-de-datos-masivos]]"
---

# SparkSQL

## Summary


## Key Ideas
- DataFrame
  - Distributed collection of data organized into named columns.
- Catalyst Optimizer
  - Query optimization framework used by **Spark SQL**.

## Spark SQL Architecture.

- **SQL Parser**: Parses SQL queries into and abstract syntax tree.
- **Catalyst optimizer**: Optimizes the AST into an efficient execution plan.
- **Execution Engine**: Executes the optimized plan on the cluster.

## SQL Querying using spark
- `filter()`
	- filter rows based on condition.

```python
from pyspark.sql.fuctions import col

filtered_df = df.filter(col("temperature") > 100)
```

- `count()`
	- returns the number of records.

```python
record_count = df.count()
```

- `orderBy()`	
	- sort DF rows in ascending or descending order.

```python
ordered_df = df.orderBy(col("temperature"), ascending=False)
```

- `groupBy()`
	- used to group data based on one or more columns. Allows performing aggregate functions.

```python
grouped_df = df.groupBy("machine").count()
```

- Aggregate functions
	- `avg`
	- `min`
	- `max`

```python
from pyspark.sql.functions import avg, min, max

agg_df = df.groupBy("machine").agg(
	avg("temperature").alias("avg_temp"),
	min("temperature").alias("min_temp"),
	max("temperature").alias("max_temp")
)

agg_df.show()
```


## Related Links
- [[ ]]

## Source
[text](url) 

