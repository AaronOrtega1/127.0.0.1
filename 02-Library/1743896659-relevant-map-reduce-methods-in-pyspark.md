---
aliases:
  - relevant-map-reduce-methods-in-pyspark
tags:
  - #resource
created_date: "2025-04-05"
link: "[[1743811421-procesamiento-de-datos-masivos|Procesamiento De Datos Masivos]]"
---

# relevant-map-reduce-methods-in-pyspark

## Summary


## Key Ideas
### Relevant MapReduce Methods in PySpark

```python {file: example-map-reduce.ipynb}
map()
flatMap()
reduceByKey()
groupByKey()
countByValue()
```

- `map()`
	- Apply a function to each element in the RDD.
- `flatMap()`
	- Apply a function that returns an iterable, and flatten the results.
- `reduceByKey()`
	- Combine values for each key using a reduce function.
- `groupByKey()`
	- Groups all values with the same key into and iterable.
- `countByValue()`
	- Used to count the occurrences of each unique value in and RDD.
- `filer()`
	- Used to filter elements of and RDD based on a condition defined in a function.

## Related Links
- [[ ]]

## Source
[text](url) 

