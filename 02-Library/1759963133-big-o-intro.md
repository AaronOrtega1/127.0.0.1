---
link: "[[1759955068-master-the-java-blades-data-structures-&-algorithms|Master the Java Blades: Data Structures & Algorithms]]"
aliases:
  - Big O intro
tags:
  - Knowledge
  - BigO
  - DSA
created_date: 2025-10-08
---
# Big O intro
## Summary
- It's a way to compare mathematically how efficient a code is.
- Has **Time Complexity** which is measured in the number of operations that it takes to complete something.
- Has **Space Complexity** which is measured by how much memory a code takes to solve a problem.
### Notation
- $\Omega$ is used to denote the **best** case.
- $\Theta$ is used to denote the **average** case.
- $O$ is used to denote the **worst** case.

#### Examples and Simplify Notation 
- $O(1)$ -> is **constant**.
	- As $n$ grows the number of operations stay constant, is the **most efficient** Big O.
- $O(log\ n)$ -> is **logarithmic**.
	- As the n grows it take $2^?$ to get to the result. ($2^?=n$)
- $O(n)$ -> is **linear** to $n$ (number of cases). 
	- We can also get $O(2n)$ if we have two for loops, but to simplify we **drop the constant**. It doesn't matter if it's 2 or 1000 we drop it so we have $O(n)$.
```java
for (int j = 0; j < n; j++) {
	System.out.println(j);
}
```
- $O(n²)$ -> is **quadratic** to $n$ (number of cases)².
	- We can also get $O(n²+n)$ by adding an extra for loop outside the nested for loops but $n²$ grows faster than the $n$, and as $n$ grows bigger the stand alone $n$ becomes less significant so we **drop the non-dominant** and have only $O(n²)$.
```java
for (int j = 0; j < n; j++) {
	for (int j = 0; j < n; j++) {
		System.out.println(i + " " + j);
	}
}
```

## Related Links
- [[1744043004-big-o-timer-and-space-complexity|Big O Timer And Space Complexity]]
## Source
[text]()
